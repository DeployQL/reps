from llama_cpp import Llama

DefaultQueryLLM = Llama(model_path="/home/mtbarta/deployql/reps/results/llama-2-7b-32k-instruct.Q4_K_M.gguf", echo=False)